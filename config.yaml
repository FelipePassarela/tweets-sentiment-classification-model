training:
  epochs: 10
  batch_size: 128
  learning_rate: 6.0e-5
  optimizer: "adamw" 
  num_workers: 4
  pin_memory: true
  early_stopping:
    patience: 3
    min_delta: 0.001
    mode: "min"
    checkpoint_path: "output/models/"
  scheduler:
    name: "one_cycle"
    params:
      pct_start: 0.3 
      max_lr: 11.0e-5
      div_factor: 25
      final_div_factor: 1000
  loss_fn: "cross_entropy"

model:
  model:
  embedding_dim: 384
  hidden_dim: 256
  output_dim: 3
  n_layers: 3
  bidirectional: true
  dropout: 0.1

data:
  raw:
    training: "data/raw/twitter_training.csv"
    validation: "data/raw/twitter_validation.csv"
    test: "data/raw/twitter_test.csv"
  processed:
    training: "data/processed/twitter_training.csv"
    validation: "data/processed/twitter_validation.csv"
    test: "data/processed/twitter_test.csv"
  label_map:
    Irrelevant: 1
    Negative: 0
    Neutral: 1
    Positive: 2
  num_classes: 3
  tokenizer:
    name: "cardiffnlp/twitter-roberta-base-sentiment-latest"
    max_length: 128
  train_val_split: 0.8

wandb:
  project_name: "twitter-sentiment-analysis"
  entity: "wandb"
